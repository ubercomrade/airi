{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465a62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchmetrics.classification import (\n",
    "    AUROC,\n",
    ")\n",
    "from torchmetrics import (\n",
    "    PearsonCorrCoef,\n",
    "    SpearmanCorrCoef,\n",
    "    R2Score\n",
    ")\n",
    "\n",
    "import ast\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748da9f",
   "metadata": {},
   "source": [
    "# Check data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c6031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/user11/data/data_processed/data.tsv\", sep=\"\\t\", names=[\"peptide\", \"score\", \"hla\"])\n",
    "embeddings_table = pd.read_csv(\"/home/user11/data/embeddings_proteins/wide_data.tsv\", sep=\"\\t\")\n",
    "\n",
    "i = 1\n",
    "\n",
    "train = pd.read_csv(f\"/home/user11/data/data_processed/train{i}\", sep=\"\\t\", names=[\"peptide\", \"score\", \"hla\"])\n",
    "train.hla = train.hla.str.replace(\"_\", \"\")\n",
    "train_data = pd.merge(train, embeddings_table, on=[\"peptide\", \"score\", \"hla\"])\n",
    "\n",
    "val = pd.read_csv(f\"/home/user11/data/data_processed/test{i}\", sep=\"\\t\", names=[\"peptide\", \"score\", \"hla\"])\n",
    "val.hla = val.hla.str.replace(\"_\", \"\")\n",
    "val_data = pd.merge(val, embeddings_table, on=[\"peptide\", \"score\", \"hla\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28ec3261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peptide                                                DLDKKETVWHLEE\n",
       "score                                                            0.0\n",
       "hla                                            HLA-DPA10103-DPB10201\n",
       "alpha_id                                                    DPA10103\n",
       "beta_id                                                     DPB10201\n",
       "alpha_seq          MRPEDRMFHIRAVILRALSLAFLLSLRGAGAIKADHVSTYAAFVQT...\n",
       "beta_seq           MMVLQVSAAPRTVALTALLMVLLTSVVQGRATPENYLFQGRQECYA...\n",
       "alpha_path         /home/user11/data/embeddings_proteins/emb_esmc...\n",
       "beta_path          /home/user11/data/embeddings_proteins/emb_esmc...\n",
       "interface                         YAFFMFSGGAILNTLFGQFEYFDIEEVRMHLGMT\n",
       "peptide_path       /home/user11/data/embeddings_proteins/emb_esmc...\n",
       "alpha_positions    [39, 41, 52, 54, 61, 82, 83, 88, 89, 91, 95, 9...\n",
       "beta_positions     [37, 39, 38, 52, 54, 56, 73, 83, 93, 96, 97, 1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c8f8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHCSequenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        _, score, _, _, _, _, _, alpha_path, beta_path, _, peptide_path, alpha_positions, beta_positions = train_data.loc[idx]\n",
    "        \n",
    "        alpha_embeddings = np.load(alpha_path)[:, ast.literal_eval(alpha_positions), :].squeeze(0)\n",
    "        beta_embeddings = np.load(beta_path)[:, ast.literal_eval(beta_positions), :].squeeze(0)\n",
    "        peptide_embeddings = torch.FloatTensor(np.load(peptide_path))\n",
    "        #binding = torch.tensor(score > 0.5).to(torch.long)\n",
    "\n",
    "        return torch.FloatTensor(np.concatenate([alpha_embeddings, beta_embeddings], axis=0)), \\\n",
    "                F.pad(peptide_embeddings, (0, 0, (21 - peptide_embeddings.shape[1]) // 2, 21 - peptide_embeddings.shape[1] - (21 - peptide_embeddings.shape[1]) // 2), 'constant', value=0).squeeze(0), \\\n",
    "                torch.tensor(score, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a278324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MHCSequenceDataset(train)\n",
    "val_dataset = MHCSequenceDataset(val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=8)\n",
    "\n",
    "#len(train_dataset), train_dataset[30][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "688e9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0][2].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95533b7",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e653b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2) * -(torch.log(torch.tensor(10000.0)) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # [1, max_len, dim]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "class CrossAttentionIC50Model(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        self.protein_pos = PositionalEncoding(d_model, max_len=34)\n",
    "        self.peptide_pos = PositionalEncoding(d_model, max_len=21)\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_feedforward, 1),\n",
    "            nn.Sigmoid(),  # т.к. IC50 нормализован от 0 до 1\n",
    "        )\n",
    "\n",
    "    def forward(self, protein, peptide):\n",
    "        \"\"\"\n",
    "        protein: [B, 34, 1152]\n",
    "        peptide: [B, L, 1152] (L ∈ [9, 21])\n",
    "        \"\"\"\n",
    "\n",
    "        B, L, D = peptide.size()\n",
    "\n",
    "        # позиционная кодировка\n",
    "        protein = self.protein_pos(protein)\n",
    "        peptide_fwd = self.peptide_pos(peptide)\n",
    "        peptide_rev = self.peptide_pos(torch.flip(peptide, dims=[1]))\n",
    "\n",
    "        # cross-attention (protein queries, peptide keys/values)\n",
    "        attn_out_fwd, _ = self.cross_attn(query=protein, key=peptide_fwd, value=peptide_fwd)\n",
    "        attn_out_rev, _ = self.cross_attn(query=protein, key=peptide_rev, value=peptide_rev)\n",
    "\n",
    "        # Инвариантность ориентации — усреднение\n",
    "        attn_out = (attn_out_fwd + attn_out_rev) / 2  # [B, 34, 1152]\n",
    "\n",
    "        # Пулинг по белку (например, mean pooling)\n",
    "        pooled = attn_out.mean(dim=1)  # [B, 1152]\n",
    "\n",
    "        return self.mlp(pooled)  # [B, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf3841",
   "metadata": {},
   "source": [
    "# Create lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c74c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        self.model = model\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.train_metrics_regression = self._make_metrics_regression(\"train_\")\n",
    "        self.validation_metrics_regression = self._make_metrics_regression(\"validation_\")\n",
    "        self.train_metrics_classification = self._make_metrics_classification(\"train_\")\n",
    "        self.validation_metrics_classification = self._make_metrics_classification(\"validation_\")\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        self.cutoff = 1.0 - np.log(500) / np.log(50000)\n",
    "\n",
    "    def _make_metrics_classification(self, prefix):\n",
    "        metrics = torchmetrics.MetricCollection(\n",
    "            {\n",
    "               \"auroc\": AUROC(num_classes=2, task=\"binary\")\n",
    "            },\n",
    "            prefix=prefix)\n",
    "        return metrics\n",
    "\n",
    "    def _make_metrics_regression(self, prefix):\n",
    "        metrics = torchmetrics.MetricCollection(\n",
    "            {\n",
    "                \"pcc\": PearsonCorrCoef(),\n",
    "                \"srcc\": SpearmanCorrCoef(),  \n",
    "                \"r2\": R2Score(),             \n",
    "            },\n",
    "            prefix=prefix)\n",
    "        return metrics\n",
    "\n",
    "    def forward(self, mhc_embeddings, peptide_embeddings):\n",
    "        return self.model(mhc_embeddings, peptide_embeddings)\n",
    "\n",
    "    def _evaluate(self, batch, stage=None):\n",
    "        mhc_embeddings, peptide_embeddings, scores = batch\n",
    "        logits = self.forward(mhc_embeddings, peptide_embeddings).squeeze(1)\n",
    "        binary_logits = logits >= self.cutoff\n",
    "        loss = self.loss_fn(logits, scores) \n",
    "\n",
    "        \n",
    "\n",
    "        metrics_dict = {f\"{stage}_loss\": loss}\n",
    "\n",
    "        if stage == 'validation':\n",
    "            val_metrics_regression = self.validation_metrics_regression(logits, scores)\n",
    "            val_metrics_classification = self.validation_metrics_classification(binary_logits, scores)\n",
    "            metrics_dict.update(val_metrics_regression)\n",
    "            metrics_dict.update(val_metrics_classification)\n",
    "        elif stage == 'train':\n",
    "            train_metrics_regression = self.train_metrics_regression(logits, scores)\n",
    "            train_metrics_classification = self.train_metrics_classification(binary_logits, scores)\n",
    "            metrics_dict.update(train_metrics_regression)\n",
    "            metrics_dict.update(train_metrics_classification)\n",
    "\n",
    "            self.log_dict(metrics_dict, \n",
    "                          on_step=True, \n",
    "                          on_epoch=False, \n",
    "                          sync_dist=True, \n",
    "                          prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._evaluate(batch, stage='train')\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.train_metrics_classification.reset()\n",
    "        self.train_metrics_regression.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._evaluate(batch, stage='validation')        \n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Логируем валидационные метрики\n",
    "        self.log_dict(self.validation_metrics_regression.compute(), \n",
    "                      on_step=False, \n",
    "                      on_epoch=True, \n",
    "                      sync_dist=True, \n",
    "                      prog_bar=True)\n",
    "        self.validation_metrics_regression.reset()\n",
    "\n",
    "        self.log_dict(self.validation_metrics_classification.compute(), \n",
    "                      on_step=False, \n",
    "                      on_epoch=True, \n",
    "                      sync_dist=True, \n",
    "                      prog_bar=True)\n",
    "        self.validation_metrics_classification.reset()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), \n",
    "                                      lr=self.learning_rate, \n",
    "                                      weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"validation_auroc\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1275544",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = '/home/user11/results/logs/'\n",
    "log_csv_path = '/home/user11/results/logs_csv/'\n",
    "checkpoints_path = '/home/user11/results/models/'\n",
    "EPOCHS = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7204138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user11/.conda/envs/esm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CrossAttentionIC50Model'\n",
    "model = LModel(CrossAttentionIC50Model(),\n",
    "               learning_rate=3e-4,\n",
    "               weight_decay=1e-3,\n",
    "               )\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(name=f\"{model_name}\", save_dir=log_path)\n",
    "logger_csv = pl_loggers.CSVLogger(name=f\"{model_name}\", save_dir=log_csv_path)\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(checkpoints_path, f\"{model_name}\", f\"version_{logger_csv.version}\", \"checkpoints\"),\n",
    "    filename=\"model-epoch={epoch:02d}\",\n",
    "    save_top_k=-1,\n",
    "    every_n_epochs=1,\n",
    "    save_on_train_epoch_end=True,\n",
    ")\n",
    "\n",
    "best_iou_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(checkpoints_path, f\"{model_name}\", f\"version_{logger_csv.version}\", \"checkpoints\"),\n",
    "    filename=\"best_model_epoch={epoch:02d}-auroc={auroc:.4f}\",\n",
    "    monitor=\"validation_auroc\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    save_on_train_epoch_end=True,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"validation_auroc\", patience=10, mode=\"max\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    devices=[0],\n",
    "    default_root_dir=f'{checkpoints_path}/{model_name}',\n",
    "    logger=[logger, logger_csv],\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    callbacks=[best_iou_callback, early_stop, TQDMProgressBar(refresh_rate=1)],\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd617cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name                              | Type                    | Params | Mode \n",
      "--------------------------------------------------------------------------------------\n",
      "0 | model                             | CrossAttentionIC50Model | 7.7 M  | train\n",
      "1 | train_metrics_regression          | MetricCollection        | 0      | train\n",
      "2 | validation_metrics_regression     | MetricCollection        | 0      | train\n",
      "3 | train_metrics_classification      | MetricCollection        | 0      | train\n",
      "4 | validation_metrics_classification | MetricCollection        | 0      | train\n",
      "5 | loss_fn                           | MSELoss                 | 0      | train\n",
      "--------------------------------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.706    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e97c1ce87c24fc8bea069c3e84a3462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07520a1a9ac9455a89326950e1c25906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user11/.conda/envs/esm/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1b37975ff5452bb1552c112fcfbaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc51aa897d754c96abe796e382c11d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6209c6686c44a22bc8131761478f3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cec8ae73514b819a9b6990fe309ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3defe7ab473419b9cd6bb635f864823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d791efac354cffbeef976f5c01452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd854bc102346948388485dc22e2ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a93a0e7c154915ab4821412b9b18fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d9fd8da19e4206a51b611a7be5b8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f9d4c6ad2649ae953f417de662f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27776b9e2d134cbdb2d3c597c2dc7e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f10df3904c4da6bfcc09bd22bc3ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fa7d3177f54425b223e682ece171c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a89eb1f50f4186be5e4696be8407cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb3ad3ac89f4ec28a438543dece7a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82aaf7500ee485d95ac02bf397bb6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470cfa67f70b43df866f11e1987b37d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b50ea1d08d04ed8bfe4c2c73b741331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e5c7f860f14a1992deed82c411458f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e028e806b54011b83f6af84b1154e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413f23a792f84b54b172cd36e178dbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_kernel",
   "language": "python",
   "name": "esm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
